# -*- coding: utf-8 -*-
"""Lab8_kNN_GridSearchCV (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GFTFG3yFg2sqAPlQsKRB40XhO1WjOM3g

## Hyperparameter Tuning for kNN for Predicting Heart Disease

1. Import "heart.csv".
"""

from google.colab import files
uploaded = files.upload()

"""2. Import Library"""

import pandas as pd
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import GridSearchCV

"""3. Load the Dataset into a frame"""

df = pd.read_csv('/content/heart.csv')

"""4. Print the description, dimensions and first five records of the frame."""

print(df.info())
print(df.shape)
print(df.head())

"""5. Check whether the data has any  missing value in any column. """

df.isnull().sum()

"""6. Check whether the data has balanced class distribution. Class target = 0 indicates "Heart Disease" and target = 1 indicates "No Heart Disease". """

sns.countplot(df['target'])

"""7. Create input features X, target Y, classifier object, train-test-split using 80-20% split """

x = df.drop(columns=['target'])
y = df['target']
knn = KNeighborsClassifier()
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)

"""8. Train model"""

#Training the model
knn.fit(x_train, y_train)

"""9. Validate model on test set"""

y_pred = knn.predict(x_test)

"""10. Print Classification Report on test data"""

print(classification_report(y_test, y_pred))

"""11. Print AUC score on test data"""

roc_auc_score(y_test, y_pred)

"""The performance of the model is vey poor. Hence hyperparameters of kNN to be tuned using GridSearchCV.

12. Hyperparameter tuning using GridSearchCV. Set the parameters a)leaf-size= 1 to 15, b)n_neighbors = 1 to 10 and c) distance metric, p = 1, 2. When p =1 its Manhattan and p = 2 its Euclidean distance. GridSearchCV uses CV to search for the optimal values of the hyperparameters. It accepts the hyperparameters as a dictionary.
"""

leaf_size = list(range(1,15))
n_neighbors = list(range(1,10))
p=[1,2]   
hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)

"""13. Train a new kNN model using GridSearchCV."""

knn_2 = KNeighborsClassifier()
clf = GridSearchCV(knn_2, hyperparameters, cv=10, scoring = 'roc_auc')
best_model = clf.fit(x,y)

"""14. Print the best values of the hyperparameters."""

#Nilai hyperpaameters terbaik
print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])
print('Best p:', best_model.best_estimator_.get_params()['p'])
print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])
print('Best Score:', best_model.best_score_)

"""15. Validate the model on test data"""

y_pred = best_model.predict(x_test)

"""16. Print classification report and AUC score of the model on test data"""

print(classification_report(y_test, y_pred))
print("AUC SCORE is",roc_auc_score(y_test, y_pred))